{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPg4iLhyMNy+7fpUUBqmYOP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jhansipothabattula/Machine_Learning/blob/main/Day58.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building CNN Architectures with PyTorch"
      ],
      "metadata": {
        "id": "uY4zPNIR-CPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building CNN Architectures in PyTorch Using the nn Module**\n",
        "\n",
        "## Key Steps\n",
        "\n",
        "### 1. Define a Model\n",
        "- Use **torch.nn.Module** to build CNN layers like:\n",
        "  - convolutional layers\n",
        "  - pooling layers\n",
        "  - fully connected layers\n",
        "\n",
        "### 2. Forward Pass\n",
        "- Define how input flows through the layers to produce output\n",
        "\n",
        "### 3. Model Summary\n",
        "- Inspect the structure and learnable parameters\n"
      ],
      "metadata": {
        "id": "Ln9x6_6v-IVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Evaluating CNNs in PyTorch\n",
        "\n",
        "## Training\n",
        "- Perform forward and backward passes\n",
        "- Calculate loss\n",
        "- Update weights using an optimizer\n",
        "\n",
        "## Evaluation\n",
        "- Test the model on unseen data\n",
        "- Compute metrics like accuracy and loss\n"
      ],
      "metadata": {
        "id": "idx8H7xY-2TK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimenting with CNN Model Design and Tuning Hyperparameters\n",
        "\n",
        "## Experimentation Areas\n",
        "\n",
        "### 1. Layer Depth\n",
        "- Add or remove convolutional and pooling layers to observe the impact\n",
        "\n",
        "### 2. Filter Size\n",
        "- Experiment with kernel sizes (e.g., 3 × 3, 5 × 5)\n",
        "\n",
        "### 3. Learning Rate\n",
        "- Adjust the learning rate to improve convergence speed and accuracy\n"
      ],
      "metadata": {
        "id": "e-_JT_t6_A9F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objective**\n",
        "- Build, train, evaluate and experiment with CNNs for CIFAR-10 classification using PyTorch"
      ],
      "metadata": {
        "id": "uWkHqO9V_M76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define Transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_dataset = datasets.CIFAR10(root=\"./data\",train=True,download=True,transform=transform)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root=\"./data\",train=False,download=True,transform=transform)\n",
        "\n",
        "# Create Data Loaders\n",
        "train_loader = DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset,batch_size=64,shuffle=False)\n",
        "\n",
        "print(f\"Number of training examples: {len(train_dataset)}\")\n",
        "print(f\"Number of test examples: {len(test_dataset)}\")\n",
        "\n",
        "# Define a CNN model:\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN,self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.pool(torch.relu(self.conv1(x)))\n",
        "      x = self.pool(torch.relu(self.conv2(x)))\n",
        "      x = x.view(-1, 16 * 5 * 5)\n",
        "      x = torch.relu(self.fc1(x))\n",
        "      x = torch.relu(self.fc2(x))\n",
        "      x = self.fc3(x)\n",
        "      return x\n",
        "model = SimpleCNN()\n",
        "print(model)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Loop\n",
        "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            # Zero gradient\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward Pass\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Calculate Loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward Pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "train_model(model, train_loader, criterion, optimizer)\n",
        "\n",
        "# Evaluation loop\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f\"Test Accuracy:{100 * correct / total:.2f}%\")\n",
        "\n",
        "evaluate_model(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQwAvIYN_oX9",
        "outputId": "24b75456-1cee-412d-9507-4fa6a1dd66b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 50000\n",
            "Number of test examples: 10000\n",
            "SimpleCNN(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "Epoch [1/10], Loss: 2.3044\n",
            "Epoch [2/10], Loss: 2.3034\n",
            "Epoch [3/10], Loss: 2.3023\n",
            "Epoch [4/10], Loss: 2.3013\n",
            "Epoch [5/10], Loss: 2.3000\n",
            "Epoch [6/10], Loss: 2.2985\n",
            "Epoch [7/10], Loss: 2.2964\n",
            "Epoch [8/10], Loss: 2.2935\n",
            "Epoch [9/10], Loss: 2.2889\n",
            "Epoch [10/10], Loss: 2.2817\n",
            "Test Accuracy:16.27%\n"
          ]
        }
      ]
    }
  ]
}